{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "620576fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HELLO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HELLO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from spellchecker import SpellChecker\n",
    "from emot.emo_unicode import UNICODE_EMOJI # For emojis\n",
    "from emot.emo_unicode import EMOTICONS_EMO # For EMOTICONS\n",
    "from pyvi import ViTokenizer\n",
    "from pyvi import ViUtils\n",
    "from textblob import TextBlob  # Đảm bảo bạn đã cài đặt thư viện TextBlob và các phiên bản liên quan\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "f = open(\"./Downloads/vietnamese-stopwords.txt\", \"r\", encoding=\"utf-8\")\n",
    "#Get Stop words Dictionaries\n",
    "List_StopWords=f.read().split(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6f124c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_dict = {'j':'gì','kg':'không','dt':'điện thoại','omgruồi':' ra con ruồi','vs':'với','kbh':'không bao giờ',\n",
    "               'nvien':'nhân viên','nc':'nước','fvu':'phục vụ','r':'rồi','ctr':'chương trình','xongg':'xong','nv':'nhân viên','ntn':'như thế nào','đc':'được','ko':'không','k':'không','vs':'vệ sinh','bt':'bình thường','pai':'phải','p':'phải','ng':'người','ms':'mới','hq':'hàn quốc','r':'rồi','tok':'tokboki','v':'vậy','zé':'thấy','h':'giờ','hnay':'hôm nay','ko':'không','cóa':'có','mib':'mình','mik':'mình','hbua':'hôm bữa','vk':'vợ','ck':'chồng','sd':'sử dụng','wan jong':'quan trọng','wan':'quán','g':'giờ','n':'nguyễn','bthg':'bình thường','qa':'qua','ngta':'người ta'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d582b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory_path = r\"./Downloads/Data3/\"\n",
    "\n",
    "# Nhập các từng dữ liệu text vào data\n",
    "def xuly_data():\n",
    "    data = []\n",
    "    \n",
    "    # List all files in the directory\n",
    "    file_list = os.listdir(directory_path)\n",
    "    \n",
    "    for file_name in file_list:\n",
    "        # Check if the file is a text file (optional)\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            # Create the full file path\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "            # Read the content of the file and append it to the data list\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                file_data = f.read()\n",
    "                data.append(file_data)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec49f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xuly_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be2564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xuly_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f921659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerdata(data):\n",
    "    # Chuyển văn bản thành chữ thường\n",
    "    data_lower = [d.lower() for d in data]\n",
    "    return data_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5f584ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lower = lowerdata(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8545eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0175b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deldaucau(data_lower):\n",
    "    # Xóa tất cả các dấu câu trừ dấu chấm \".\"\n",
    "    data_cleaned = []\n",
    "    for d in data_lower:\n",
    "        # Xóa tất cả các dấu câu trừ dấu chấm \".\"\n",
    "        cleaned_text = re.sub(r'[.,\\/#!$%\\^&\\*;:{}=\\-`~()<>\"\"?@+]', '', d)\n",
    "        data_cleaned.append(cleaned_text)\n",
    "    return data_cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f86076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_punctuation = deldaucau(data_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "779361c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delnumber(data_no_punctuation):\n",
    "    # Xóa chữ số\n",
    "    data_cleaned = []\n",
    "    for d in data_no_punctuation:\n",
    "        cleaned_text = re.sub(r'\\b\\w*\\d\\w*\\b', ' ', d)\n",
    "        data_cleaned.append(cleaned_text)\n",
    "    return data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0bdb514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_numbers = delnumber(data_no_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4f48986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tachcau(data_no_numbers):\n",
    "    # Tách câu\n",
    "    data_sentences = [nltk.sent_tokenize(d) for d in data_no_numbers]\n",
    "    return data_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "859299b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sentences = tachcau(data_no_numbers)\n",
    "# Gộp các câu thành một văn bản text\n",
    "combined_text = \" \".join([\" \".join(sentences) for sentences in data_sentences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d24bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3a8aa0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_emojis(text):\n",
    "    for x in EMOTICONS_EMO:\n",
    "        text = text.replace(x, \"_\".join(EMOTICONS_EMO[x].replace(\",\", \"\").replace(\":\", \"\").split()))\n",
    "    for x in UNICODE_EMOJI:\n",
    "        text = text.replace(x, \"_\".join(UNICODE_EMOJI[x].replace(\",\", \"\").replace(\":\", \"\").split()))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bd93adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_emojis = converting_emojis(combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974b0c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_without_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b8fd41ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_stdd(text):\n",
    "    with open('./Downloads/standard-vietnamese.txt', 'r', encoding='utf-8') as standard_vietnamese_file:\n",
    "        pairs = [line.strip().split(\"=\")[0] + \"=\" + line.strip().split(\"=\")[1] for line in standard_vietnamese_file]\n",
    "        for pair in pairs:\n",
    "            key = pair.split(\"=\")[0]\n",
    "            value = pair.split(\"=\")[1]\n",
    "            text = text.replace(key, value)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "44d98a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stand=data_stdd(data_without_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22629b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b145fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_Stop_words(text):\n",
    "    #remove stop words\n",
    "    text_pre=\" \".join(text for text in text.split() if text not in List_StopWords)\n",
    "    return text_pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2e32dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_stopwords = remove_Stop_words(data_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63352276",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e442b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_std(input_text):\n",
    "    words = input_text.split()\n",
    "    # Get Abbreviations Words\n",
    "    text_pre=\"\"\n",
    "    for word in words:\n",
    "        w=word\n",
    "        w = re.sub(r'[^\\w\\s]','',w) #Removing Punctuation\n",
    "        if w.lower() in lookup_dict:\n",
    "            word=lookup_dict[w]\n",
    "        text_pre=text_pre + \" \" + word        \n",
    "    return text_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "903c0c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Preprocessing = data_std(data_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5408300a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Data_Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b46d8777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã xử lý đã được lưu vào ./Downloads/Data3/Data3/Data_Preprocessing/Data_Preprocessing.txt\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn đến tệp output\n",
    "output_file_path = \"./Downloads/Data3/Data/Data_Preprocessing/Data_Preprocessing.txt\"\n",
    "\n",
    "# Lưu dữ liệu đã xử lý vào tệp văn bản\n",
    "with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "    output_file.write(Data_Preprocessing)\n",
    "\n",
    "print(f\"Dữ liệu đã xử lý đã được lưu vào {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a44bdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
